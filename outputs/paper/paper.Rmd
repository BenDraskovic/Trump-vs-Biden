---
title: "TBD"
subtitle: "TBD"
author: "TBD"
thanks: "Code and data are available at: LINK."
date: "`r format(Sys.time(), '%d %B %Y')`"
abstract: |
  | First sentence. Second sentence. Third sentence. Fourth sentence. 
output:
  bookdown::pdf_document2:
toc: FALSE
bibliography: references.bib
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

# Introduction


# Data


# Model

The model we use to predict the result of the election is MRP, multilevel regression with post-stratification. Logistic regression allows us the simplicity of analyzing the categorical response variable while incorporating both numerical and categorical explanatory variables; while combined with post-stratification it yields a prediction result closer to the population parameter.

We are interested in how variables such as age, education, race, family income, and geographic region affect citizensâ€™ voting intentions. The response variable that we are interested in is the chances of a citizen voting for Trump in the coming presidential election. It is a categorical variable with two levels: 1 represents intending to vote for Donald Trump, and 2 means planning to vote for Joe Biden.

First, we train a multilevel logistic regression model using raw data obtained from the voter study group towards the variable of interest using the 7 explanatory variables. We then apply this model to our post-stratification data set to get the estimates. 

Logistic regression estimates $\beta_0...\beta_k$ in equation \@ref(eq:logistic)

\begin{equation}
log(\frac{p}{1-p})=\beta_0+\beta_1x_1+...+\beta_kx_k (\#eq:logistic)
\end{equation}

where p is the probability of event A that we are interested in, $\beta_0$is the intercept, $x_1...x_K$ are our variables of interest and $\beta_1...\beta_k$ are parameters for each of these variables. Based on the result, we are able to estimate p for a particular case given all the variables.

The logic behind post-stratification is that we divide the sample data into strata based on a few attributes such as state, income, education level. Then we come up with a weight for each stratum to adjust its influence towards our prediction. Namely, if a stratum is over-represented, we want to reduce its impact on the prediction result; if a stratum is under-represented, we want to increase its influence.
We need a post-stratification dataset that is large enough to do this. In this report, we use the ACS(reason). 

The post-stratification estimate is defined by $\hat{y}_{PS} = \frac{\sum{N_j\hat{y}_j}}{\sum{N_j}}$ where $\hat{y}_j$ is the estimate of y in cell j, and $N_j$ is the size of the j-th cell in the population. An illustration using the education variable is $\hat{y}_{edu}^{PS} = \frac{\sum_{j\in J_{edu}}{N_j\hat{y}_j}}{\sum_{j\in J_{edu}}{N_j}}$, we can get an estimation given any level of education of respondents, $J_{edu}$ denotes all subsets of education levels, $\cup_{i\in J} J^{edu}_{i} =$ all possible education levels. 

The multilevel regression before post-stratification produces a proportion for the post-stratification based on regression, instead of merely averaging the sample in each stratum. Specifically, all possible combinations of cells are from combining: 

-
-
-
-
-
-

We fit the logistic regressions for estimating candidate support in each cell. We used `function` from `package` to fit \@ref(eq:model).

\begin{equation}
P(Trump) = logit^{-1}(
\beta_0 + \beta_age + \beta_{j[i]}^{edu} + \beta_{j[i]}^{race}
+ \beta_{j[i]}^{income} + \beta_{j[i]}^{state} + \beta_{j[i]}^{mask}
) (\#eq:model)
\end{equation}

\@ref(eq:model) is the model that we fit using the survey data, with $\beta_{j[i]}^{var} \sim N(0, \sigma^2_{var})$. 
$\beta_0$ is the intercept,each of $\beta_{j[i]}^{var}$ represents the parameter for the i-th respondent in j-th cell. For example, $\beta_{j[i]}^{state}$ can take values from $\beta$ for all states in the US. Then the model sums up estimates for each cell to the population. 

We find the mask parameter interesting, firstly because US is the country with the most COVID cases in the world, the influence of COVID on election choices is inevitable. Secondly, since Trump and Biden have very opposites towards the pandemic and how to handle it, this parameter will likely represent part of respondent's voting intention in the same way as any more common political indicators. 

# Results

```{r}
fit <- stan_glmer(#try using glmer()
  binary ~ factor(male) + factor(male) * factor(age) +
    (1 | state) + (1 | age) + (1 | eth) + (1 | income),
  family = binomial(link = "logit"),
  data = clean_survey#all age, state etc coming from post-strat
)
```

```{r}
# to get the estimated proportions and associated 95% PIs by state
res_state <- fit %>%
  add_predicted_draws(newdata=state_prop %>% 
                        filter(age_group>20, age_group<80, decade_married>1969),
                      allow_new_levels=TRUE) %>%
  rename(kept_name_predict = .prediction) %>% 
  mutate(kept_name_predict_prop = kept_name_predict*prop) %>% 
  group_by(state_name, .draw) %>% 
  summarise(kept_name_predict = sum(kept_name_predict_prop)) %>% 
  group_by(state_name) %>% 
  summarise(mean = mean(kept_name_predict), 
            lower = quantile(kept_name_predict, 0.025), 
            upper = quantile(kept_name_predict, 0.975))
```

```{r}
# graph by state
res_state %>% 
  arrange(-mean) %>% 
  left_join(d %>%
              group_by(state_name, kept_name) %>%
              summarise(n = n()) %>%
              group_by(state_name) %>%
              mutate(prop = n/sum(n)) %>%
              filter(kept_name==1)) %>% 
  ggplot(aes(y = mean, x = forcats::fct_inorder(state_name), color = "MRP estimate")) + 
  geom_point() +
  coord_flip() + 
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0) + 
  ylab("proportion keeping maiden name") + 
  xlab("state") + 
  geom_point(aes(state_name, prop, color = "raw data")) +
  scale_color_manual(name = "", values = c("MRP estimate" = "black", "raw data" = "red")) + 
  theme_bw() +
  ggtitle("Proportion of women keeping maiden name after marriage")


res_state %>% 
  mutate(statename = str_to_title(state_name)) %>% 
  #mutate(statename = ifelse(state_name=="district of columbia", "District of Columbia", statename)) %>% 
  ggplot(aes(fill = mean, state = statename)) + 
  geom_statebins() +
  scale_fill_viridis_c(name = "proportion keeping name") +
  theme_void()
ggsave("state_plot.png", width = 8, height = 6)
```

# Discussion

## First discussion point

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

## Third discussion point

## Weaknesses and next steps

### 1: Nested Bayesian Model /,

\newpage

# Appendix {-}

\newpage


# References


